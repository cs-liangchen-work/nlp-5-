中文论文解读：
1.https://zhuanlan.zhihu.com/p/47580077（有代码）
2.https://zhuanlan.zhihu.com/p/141622985
3.https://www.cnblogs.com/zle1992/p/9100780.html（最后的图比较好）

只关注普通的LSTM，树的LSTM放弃了。


该代码中涉及到了池化，是对句子长度的维度进行池化，也就是先将第二维度与第三维度进行交换在进行池化，想起了这也是对embedding的一种理解，每一个深度其实代表一个特征。


结果形式是这样的：
save model......
epoch 1, train_acc 0.469925, dev_acc 0.575000, test_acc 0.576000, max_acc 0.575000, time 1:55:03.473793
