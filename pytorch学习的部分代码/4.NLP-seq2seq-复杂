使用的是seq2seq的翻译模型，注意的一点是decoder的时候，每输出一个都会作为下一次的输入。

 The encoder reads an input sequence and outputs a single vector, and the decoder reads that vector to produce an output sequence.
 
 值的仔细理解一个gru的使用：
 https://zhuanlan.zhihu.com/p/37217734
 非常棒的一篇知乎文章。
1.输出的out包括了每一个输入位所对应的输出。因而输入输出的格式相同。
   指的是每经过一个hidden的输出。
2、输出的隐含层向量只返回最后一层所对应的隐含层输出。这是设计的原因是很多时候只需要使用最后一层的隐含层输出。比如Sequence to Sequence模型中的encoder一般就只传递最后一层的隐层输出给decoder。

